{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torchvision import models, datasets\n",
    "from torch import optim\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18, vgg16, alexnet\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESNET18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\Final_Projects\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\Desktop\\Final_Projects\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 1.6100254121894029\n",
      "Epoch 1 loss: 1.5042699554184231\n",
      "Epoch 2 loss: 1.4819937258095943\n",
      "Epoch 3 loss: 1.4680913475680193\n",
      "Epoch 4 loss: 1.4572801490403495\n",
      "Precision: 0.4229\n",
      "Recall: 0.4330\n",
      "F1 Score: 0.4198\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.43      0.35       958\n",
      "           1       0.00      0.00      0.00       111\n",
      "           2       0.30      0.23      0.26      1024\n",
      "           3       0.56      0.63      0.59      1774\n",
      "           4       0.43      0.39      0.41      1233\n",
      "           5       0.41      0.25      0.31      1247\n",
      "           6       0.49      0.67      0.57       831\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.36      0.37      0.36      7178\n",
      "weighted avg       0.42      0.43      0.42      7178\n",
      "\n",
      "Accuracy on the test set: 43.30%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torchvision import models, datasets\n",
    "from torch import optim\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18, vgg16, alexnet\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "class FER2013Dataset(Dataset):\n",
    "    def __init__(self, root_dir, transform = None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.label_to_idx = {}  # Dictionary to map labels to indices\n",
    "\n",
    "         # Traverse through all the folders and subfolders to collect image paths and labels\n",
    "        for idx, label in enumerate(sorted(os.listdir(root_dir))):  # Sort labels to ensure consistent ordering\n",
    "            label_dir = os.path.join(root_dir, label)\n",
    "            if os.path.isdir(label_dir):\n",
    "                self.label_to_idx[label] = idx  # Map each label to an integer index\n",
    "                for img_name in os.listdir(label_dir):\n",
    "                    img_path = os.path.join(label_dir, img_name)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(idx)  # Use index as label\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        #total no of samples\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img,label\n",
    "\n",
    "# Define the transformations to be applied to the images   \n",
    "transform = transforms.Compose([\n",
    "    \n",
    "    transforms.Resize((224,224)),  # Resize image to match pre-trained model input\n",
    "    transforms.ToTensor(),  # Convert PIL image to PyTorch tensor\n",
    "    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229,0.224, 0.225])  #Normalize\n",
    "])\n",
    "\n",
    "\n",
    "# Create an instance of the dataset\n",
    "train_dataset = FER2013Dataset(root_dir=r'C:\\Users\\USER\\Desktop\\Final_Projects\\.venv\\Emotion_Detection\\FER2013FolderDataset\\train', transform=transform)\n",
    "test_dataset = FER2013Dataset(root_dir=r'C:\\Users\\USER\\Desktop\\Final_Projects\\.venv\\Emotion_Detection\\FER2013FolderDataset\\test', transform=transform)\n",
    "\n",
    "# Create DataLoaders for training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "\n",
    "# Freeze all layers except the final layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the final layer to output 7 classes (for FER2013)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 7)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch} loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate on the test set\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Collect all true labels and predictions\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(all_labels, all_preds, target_names=[str(i) for i in range(7)])\n",
    "\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "correct = (all_preds == all_labels).sum()\n",
    "total = len(all_labels)\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set: {accuracy:.2f}%')\n",
    "\n",
    "\n",
    "# Optional: Save the model after training\n",
    "torch.save(model.state_dict(), 'fer2013_resnet18.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\Final_Projects\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\Desktop\\Final_Projects\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 1.7199949007522821\n",
      "Epoch 1 loss: 1.6844026460944943\n",
      "Epoch 2 loss: 1.6770031515898842\n",
      "Epoch 3 loss: 1.6625328877057157\n",
      "Epoch 4 loss: 1.6660226578170845\n",
      "Accuracy on the test set: 40.860964056840345%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\Final_Projects\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\USER\\Desktop\\Final_Projects\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\USER\\Desktop\\Final_Projects\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\USER\\Desktop\\Final_Projects\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4327\n",
      "Recall: 0.4086\n",
      "F1 Score: 0.3734\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.24      0.28       958\n",
      "           1       0.00      0.00      0.00       111\n",
      "           2       0.34      0.19      0.24      1024\n",
      "           3       0.44      0.74      0.55      1774\n",
      "           4       0.32      0.58      0.41      1233\n",
      "           5       0.51      0.11      0.19      1247\n",
      "           6       0.73      0.42      0.54       831\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.38      0.33      0.32      7178\n",
      "weighted avg       0.43      0.41      0.37      7178\n",
      "\n",
      "Accuracy on the test set: 40.86%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torchvision import models, datasets\n",
    "from torch import optim\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18, vgg16, alexnet\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "class FER2013Dataset(Dataset):\n",
    "    def __init__(self, root_dir, transform = None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.label_to_idx = {}  # Dictionary to map labels to indices\n",
    "\n",
    "         # Traverse through all the folders and subfolders to collect image paths and labels\n",
    "        for idx, label in enumerate(sorted(os.listdir(root_dir))):  # Sort labels to ensure consistent ordering\n",
    "            label_dir = os.path.join(root_dir, label)\n",
    "            if os.path.isdir(label_dir):\n",
    "                self.label_to_idx[label] = idx  # Map each label to an integer index\n",
    "                for img_name in os.listdir(label_dir):\n",
    "                    img_path = os.path.join(label_dir, img_name)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(idx)  # Use index as label\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        #total no of samples\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img,label\n",
    "\n",
    "# Define the transformations to be applied to the images   \n",
    "transform = transforms.Compose([\n",
    "    \n",
    "    transforms.Resize((224,224)),  # Resize image to match pre-trained model input\n",
    "    transforms.ToTensor(),  # Convert PIL image to PyTorch tensor\n",
    "    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229,0.224, 0.225])  #Normalize\n",
    "])\n",
    "\n",
    "\n",
    "# Create an instance of the dataset\n",
    "train_dataset = FER2013Dataset(root_dir=r'C:\\Users\\USER\\Desktop\\Final_Projects\\.venv\\Emotion_Detection\\FER2013FolderDataset\\train', transform=transform)\n",
    "test_dataset = FER2013Dataset(root_dir=r'C:\\Users\\USER\\Desktop\\Final_Projects\\.venv\\Emotion_Detection\\FER2013FolderDataset\\test', transform=transform)\n",
    "\n",
    "# Create DataLoaders for training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "\n",
    "# Freeze all layers except the final layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "# Modify the classifier for 7 classes (FER2013)\n",
    "num_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_features, 7)\n",
    "\n",
    "# Modify the final layer to output 7 classes (for FER2013)\n",
    "#num_features = model.fc.in_features\n",
    "#model.fc = nn.Linear(num_features, 7)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch} loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "# Evaluate on the test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print(f'Accuracy on the test set: {100 * correct / total}%')\n",
    "\n",
    "\n",
    "# Evaluate on the test set\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Collect all true labels and predictions\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(all_labels, all_preds, target_names=[str(i) for i in range(7)])\n",
    "\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "correct = (all_preds == all_labels).sum()\n",
    "total = len(all_labels)\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set: {accuracy:.2f}%')\n",
    "\n",
    "\n",
    "# Optional: Save the model after training\n",
    "torch.save(model.state_dict(), 'fer2013_VGG16.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\Final_Projects\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 1.75423906295496\n",
      "Epoch 1 loss: 1.7201677021842225\n",
      "Epoch 2 loss: 1.7166682953027415\n",
      "Epoch 3 loss: 1.689706286369825\n",
      "Epoch 4 loss: 1.6937163422394437\n",
      "Accuracy on the test set: 37.921426581220395%\n",
      "Precision: 0.4823\n",
      "Recall: 0.3792\n",
      "F1 Score: 0.3799\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.41      0.32       958\n",
      "           1       0.31      0.24      0.27       111\n",
      "           2       0.22      0.60      0.32      1024\n",
      "           3       0.70      0.41      0.52      1774\n",
      "           4       0.43      0.29      0.35      1233\n",
      "           5       0.53      0.10      0.17      1247\n",
      "           6       0.62      0.57      0.59       831\n",
      "\n",
      "    accuracy                           0.38      7178\n",
      "   macro avg       0.44      0.37      0.36      7178\n",
      "weighted avg       0.48      0.38      0.38      7178\n",
      "\n",
      "Accuracy on the test set: 37.92%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torchvision import models, datasets\n",
    "from torch import optim\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18, vgg16, alexnet\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "class FER2013Dataset(Dataset):\n",
    "    def __init__(self, root_dir, transform = None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.label_to_idx = {}  # Dictionary to map labels to indices\n",
    "\n",
    "         # Traverse through all the folders and subfolders to collect image paths and labels\n",
    "        for idx, label in enumerate(sorted(os.listdir(root_dir))):  # Sort labels to ensure consistent ordering\n",
    "            label_dir = os.path.join(root_dir, label)\n",
    "            if os.path.isdir(label_dir):\n",
    "                self.label_to_idx[label] = idx  # Map each label to an integer index\n",
    "                for img_name in os.listdir(label_dir):\n",
    "                    img_path = os.path.join(label_dir, img_name)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(idx)  # Use index as label\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        #total no of samples\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img,label\n",
    "\n",
    "# Define the transformations to be applied to the images   \n",
    "transform = transforms.Compose([\n",
    "    \n",
    "    transforms.Resize((224,224)),  # Resize image to match pre-trained model input\n",
    "    transforms.ToTensor(),  # Convert PIL image to PyTorch tensor\n",
    "    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229,0.224, 0.225])  #Normalize\n",
    "])\n",
    "\n",
    "\n",
    "# Create an instance of the dataset\n",
    "train_dataset = FER2013Dataset(root_dir=r'C:\\Users\\USER\\Desktop\\Final_Projects\\.venv\\Emotion_Detection\\FER2013FolderDataset\\train', transform=transform)\n",
    "test_dataset = FER2013Dataset(root_dir=r'C:\\Users\\USER\\Desktop\\Final_Projects\\.venv\\Emotion_Detection\\FER2013FolderDataset\\test', transform=transform)\n",
    "\n",
    "# Create DataLoaders for training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "model = models.alexnet(pretrained=True)\n",
    "\n",
    "\n",
    "# Freeze all layers except the final layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "# Modify the classifier for 7 classes (FER2013)\n",
    "num_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_features, 7)\n",
    "\n",
    "# Modify the final layer to output 7 classes (for FER2013)\n",
    "#num_features = model.fc.in_features\n",
    "#model.fc = nn.Linear(num_features, 7)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch} loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "# Evaluate on the test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print(f'Accuracy on the test set: {100 * correct / total}%')\n",
    "\n",
    "# Evaluate on the test set\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Collect all true labels and predictions\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(all_labels, all_preds, target_names=[str(i) for i in range(7)])\n",
    "\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "correct = (all_preds == all_labels).sum()\n",
    "total = len(all_labels)\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set: {accuracy:.2f}%')\n",
    "\n",
    "\n",
    "# Optional: Save the model after training\n",
    "torch.save(model.state_dict(), 'fer2013_alexnet.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
